{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AzureOpenAIModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = AzureOpenAIModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"\"\"\\\n",
    "You will be given a summary (LLM output) written for a news article and asked to evaluate its coherence compared to the original text. \n",
    "Please assess the summary based on five specific criteria, providing a true or false rating for each one, and output the results in JSON format.\n",
    "\n",
    "### Criteria for Evaluation:\n",
    "1. **Key Information Coverage**: Does the summary accurately capture the main points and critical details from the original text?\n",
    "2. **Logical Flow and Structure**: Is the summary logically structured, with ideas presented in a clear and cohesive order, mirroring the logical flow of the original text?\n",
    "3. **Factual Accuracy**: Are all factual statements in the summary accurate based on the original text, with no misrepresentations or unsupported claims?\n",
    "4. **Conciseness and Relevance**: Is the summary concise, focusing on relevant details without unnecessary information or excessive verbosity?\n",
    "5. **Terminology and Tone Consistency**: Does the summary use terminology and maintain a tone consistent with the original text, ensuring no added bias or style mismatch?\n",
    "\n",
    "### Format:\n",
    "Output your evaluation in JSON format, with each criterion labeled and rated as either true or false.\n",
    "\n",
    "Original Text:\n",
    "{input}\n",
    "\n",
    "Summary:\n",
    "{llm_output}\n",
    "\n",
    "Evaluation:\n",
    "{{\n",
    "    \"Key Information Coverage\": true/false,\n",
    "    \"Logical Flow and Structure\": true/false,\n",
    "    \"Factual Accuracy\": true/false,\n",
    "    \"Conciseness and Relevance\": true/false,\n",
    "    \"Terminology and Tone Consistency\": true/false\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\\\n",
    "Today we are releasing Stable Diffusion 3.5, our most powerful models yet. This open release includes multiple variants that are customizable, run on consumer hardware, and are available for use under the permissive Stability AI Community License. You can download Stable Diffusion 3.5 Large and Stable Diffusion 3.5 Large Turbo models from Hugging Face and the inference code on GitHub now. \n",
    "\n",
    "In June, we released Stable Diffusion 3 Medium, the first open release from the Stable Diffusion 3 series. This release didn't fully meet our standards or our communities’ expectations. After listening to the valuable community feedback, instead of a quick fix, we took the time to further develop a version that advances our mission to transform visual media. \n",
    "\n",
    "Stable Diffusion 3.5 reflects our commitment to empower builders and creators with tools that are widely accessible, cutting-edge, and free for most use cases. We encourage the distribution and monetization of work across the entire pipeline - whether it's fine-tuning, LoRA, optimizations, applications, or artwork. \n",
    "\n",
    "What’s being released\n",
    "\n",
    "Stable Diffusion 3.5 offers a variety of models developed to meet the needs of scientific researchers, hobbyists, startups, and enterprises alike:\n",
    "\n",
    "Stable Diffusion 3.5 Large: At 8 billion parameters, with superior quality and prompt adherence, this base model is the most powerful in the Stable Diffusion family. This model is ideal for professional use cases at 1 megapixel resolution.\n",
    "\n",
    "Stable Diffusion 3.5 Large Turbo: A distilled version of Stable Diffusion 3.5 Large generates high-quality images with exceptional prompt adherence in just 4 steps, making it considerably faster than Stable Diffusion 3.5 Large.\n",
    "\n",
    "Stable Diffusion 3.5 Medium (to be released on October 29th): At 2.5 billion parameters, with improved MMDiT-X architecture and training methods, this model is designed to run “out of the box” on consumer hardware, striking a balance between quality and ease of customization. It is capable of generating images ranging between 0.25 and 2 megapixel resolution. \n",
    "\n",
    "Developing the models\n",
    "\n",
    "In developing the models, we prioritized customizability to offer a flexible base to build upon. To achieve this, we integrated Query-Key Normalization into the transformer blocks, stabilizing the model training process and simplifying further fine-tuning and development.\n",
    "\n",
    "To support this level of downstream flexibility, we had to make some trade-offs. Greater variation in outputs from the same prompt with different seeds may occur, which is intentional as it helps preserve a broader knowledge-base and diverse styles in the base models. However, as a result, prompts lacking specificity might lead to increased uncertainty in the output, and the aesthetic level may vary. \n",
    "\n",
    "For the Medium model specifically, we made several adjustments to the architecture and training protocols to enhance quality, coherence, and multi-resolution generation abilities.\n",
    "\n",
    "Where the models excel\n",
    "\n",
    "The Stable Diffusion 3.5 version excels in the following areas, making it one of the most customizable and accessible image models on the market, while maintaining top-tier performance in prompt adherence and image quality:\n",
    "\n",
    "Customizability: Easily fine-tune the model to meet your specific creative needs, or build applications based on customized workflows.\n",
    "\n",
    "Efficient Performance: Optimized to run on standard consumer hardware without heavy demands, especially the Stable Diffusion 3.5 Medium and Stable Diffusion 3.5 Large Turbo models.\n",
    "\n",
    "Diverse Outputs: Creates images representative of the world, not just one type of person, with different skin tones and features, without the need for extensive prompting. \n",
    "\n",
    "View fullsize\n",
    "\n",
    "Versatile Styles: Capable of generating a wide range of styles and aesthetics like 3D, photography, painting, line art, and virtually any visual style imaginable.\n",
    "\n",
    "View fullsize\n",
    "\n",
    "Additionally, our analysis shows that Stable Diffusion 3.5 Large leads the market in prompt adherence and rivals much larger models in image quality.\n",
    "\n",
    "Stable Diffusion 3.5 Large Turbo offers some of the fastest inference times for its size, while remaining highly competitive in both image quality and prompt adherence, even when compared to non-distilled models of similar size\n",
    "\n",
    "Stable Diffusion 3.5 Medium outperforms other medium-sized models, offering a balance of prompt adherence and image quality, making it a top choice for efficient, high-quality performance.\n",
    "\n",
    "View fullsize\n",
    "\n",
    "View fullsize\n",
    "\n",
    "The Stability AI Community license at a glance\n",
    "\n",
    "We are pleased to release this model under our permissive community license. Here are the key components of the license:\n",
    "\n",
    "Free for non-commercial use: Individuals and organizations can use the model free of charge for non-commercial use, including scientific research.  \n",
    "\n",
    "Free for commercial use (up to $1M in annual revenue): Startups, small to medium-sized businesses, and creators can use the model for commercial purposes at no cost, as long as their total annual revenue is less than $1M.\n",
    "\n",
    "Ownership of outputs: Retain ownership of the media generated without restrictive licensing implications.\n",
    "\n",
    "For organizations with annual revenue more than $1M, please contact us here to inquire about an Enterprise License.\n",
    "\n",
    "More ways to access the models\n",
    "\n",
    "While the model weights are available on Hugging Face now for self-hosting, you can also access the model through the following platforms:\n",
    "\n",
    "Stability AI API \n",
    "\n",
    "Replicate\n",
    "\n",
    "ComfyUI\n",
    "\n",
    "DeepInfra\n",
    "\n",
    "Our commitment to safety\n",
    "\n",
    "We believe in safe, responsible AI practices and take deliberate measures to ensure Integrity starts at the early stages of development. This means we have taken and continue to take reasonable steps to prevent the misuse of Stable Diffusion 3.5 by bad actors. For more information about our approach to Safety please visit our Stable Safety page.\n",
    "\n",
    "Coming soon\n",
    "\n",
    "On October 29th, we will publicly release Stable Diffusion 3.5 Medium. Shortly after, ControlNets will also launch, providing advanced control features for a wide variety of professional use cases.\n",
    "\n",
    "We look forward to hearing your feedback on Stable Diffusion 3.5 and seeing what you create with the models. You can share thoughts directly with us through this form.\n",
    "\"\"\"\n",
    "\n",
    "summary = \"\"\"\\\n",
    "Stable Diffusion 3.5, Stability AI’s latest release, introduces high-quality, customizable models that run on consumer hardware, available under a permissive community license. The series includes Stable Diffusion 3.5 Large (8 billion parameters, high prompt adherence for professional-grade output), Stable Diffusion 3.5 Large Turbo (a faster, distilled version generating high-quality images in four steps), and Stable Diffusion 3.5 Medium (optimized for consumer hardware with a smaller 2.5-billion parameter setup, releasing October 29). These models focus on customizability, efficient performance, and diverse outputs across styles like 3D, photography, and painting. Users retain ownership of generated content, with free access for non-commercial use and commercial use under $1M revenue. Stability AI offers download options on Hugging Face and platforms like Stability AI API, Replicate, and ComfyUI, with safety measures in place to prevent misuse and an upcoming ControlNets feature for enhanced control.\n",
    "\"\"\"\n",
    "input_message = {\"input\": context, \"llm_output\": summary}\n",
    "result = gpt_model.run_model(\n",
    "    human_prompt=human_prompt, input_message=input_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Key Information Coverage': True, 'Logical Flow and Structure': True, 'Factual Accuracy': True, 'Conciseness and Relevance': True, 'Terminology and Tone Consistency': True}\n",
      "Score of this LLM output: 5/5\n"
     ]
    }
   ],
   "source": [
    "parsed_result = json.loads(result)\n",
    "print(parsed_result)\n",
    "print(f\"Score of this LLM output: {sum(parsed_result.values())}/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
